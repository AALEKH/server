--source include/have_innodb.inc

--disable_warnings
DROP TABLE if exists t1;
--enable_warnings

--disable_query_log
let $innodb_defragment_n_pages_orig=`select @@innodb_defragment_n_pages`;
--enable_query_log

# Create table.
CREATE TABLE t1 (a INT NOT NULL PRIMARY KEY AUTO_INCREMENT, b VARCHAR(256), KEY SECOND(a, b)) ENGINE=INNODB;

## Test-1 defragment an empty table
optimize table t1;

## Test-2 defragment a single page table
INSERT INTO t1 VALUES (100000, REPEAT('A', 256));
INSERT INTO t1 VALUES (200000, REPEAT('A', 256));
INSERT INTO t1 VALUES (300000, REPEAT('A', 256));
INSERT INTO t1 VALUES (400000, REPEAT('A', 256));

optimize table t1;

## Test-3 defragment (somewhat) in parallel with delete queries
let $data_size = 10000;
let $delete_size = 100;

delimiter //;
create procedure defragment()
begin
  set @i = 0;
  repeat
    set @i = @i + 1;
    optimize table t1;
    select sleep(5);
  until @i = 3 end repeat;
end //
delimiter ;//


# Populate table.
let $i = $data_size;
--disable_query_log
while ($i)
{
  eval
    INSERT INTO t1 VALUES ($data_size + 1 - $i, REPEAT('A', 256));
  dec $i;
}
--enable_query_log


select count(*) from t1;

if (!`select count(*) > 180 from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' order by page_number;`)
{
select count(*) from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' order by page_number;
}

select count(*) from t1 force index (second);

if (!`select count(*) > 170 from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' order by page_number;`)
{
select count(*) from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' order by page_number;
}


connect (con1,localhost,root,,test,$MASTER_MYPORT,$MASTER_MYSOCK);

connection con1;
--send call defragment()

connection default;

--disable_query_log
let $size = $delete_size;
while ($size)
{
    let $j =  100 * $size;
    eval delete from t1 where a between $j - 20 and $j;
    dec $size;
}
--enable_query_log

connection con1;
--disable_result_log
--reap
--enable_result_log

connection default;
disconnect con1;

optimize table t1;
select sleep(5);

--source include/restart_mysqld.inc
select count(*) from t1;

# After deletion & defragmentation, there are 8000 records left
if (!`select count(*) < 180 from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' order by page_number;`)
{
select count(*) from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' order by page_number;
}

select count(*) from t1 force index (second);

# secondary index is pretty much the same size as primary index so the number of pages should be similar.
if (!`select count(*) < 180 from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' order by page_number;`)
{
select count(*) from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' order by page_number;
}

## Test-4 defragment with larger n_pages

# delete some more records
--disable_query_log
let $size = $delete_size;
while ($size)
{
    let $j = 100 * $size;
    eval delete from t1 where a between $j - 30 and $j - 20;
    dec $size;
}
--enable_query_log

SET @@global.innodb_defragment_n_pages = 3;

# This will not reduce number of pages by a lot
optimize table t1;

--source include/restart_mysqld.inc

select count(*) from t1;

# We didn't create large wholes with the previous deletion, so if innodb_defragment_n_pages = 3, we won't be able to free up many pages.
if (!`select count(*) > 130 from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' order by page_number;`)
{
select count(*) from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' order by page_number;
}

select count(*) from t1 force index (second);

# Same holds for secondary index, not many pages are released.
if (!`select count(*) > 100 from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' order by page_number;`)
{
select count(*) from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' order by page_number;
}

SET @@global.innodb_defragment_n_pages = 10;

optimize table t1;

--source include/restart_mysqld.inc

select count(*) from t1;

# This time we used innodb_defragment_n_pages = 10, so we should be able to free up some pages.
if (!`select count(*) < 160 from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' order by page_number;`)
{
select count(*) from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'PRIMARY' order by page_number;
}

select count(*) from t1 force index (second);

if (!`select count(*) < 160 from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' order by page_number;`)
{
select count(*) from information_schema.innodb_buffer_page where table_name like '%t1%' and index_name = 'second' order by page_number;
}

DROP PROCEDURE defragment;
DROP TABLE t1;
# reset system
--disable_query_log
EVAL SET GLOBAL innodb_defragment_n_pages = $innodb_defragment_n_pages_orig;
--enable_query_log

